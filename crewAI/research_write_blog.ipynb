{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# CrewAI\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from textwrap import dedent\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "SERPER_API_KEY = os.getenv(\"SERPER_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents\n",
    "Here, we will be building individual agents which will work in sync to research and write a blog. For this, we will be using crewAI agents to create individual agents and combine them to fulfill the common task of researching and writing the blog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher = Agent(\n",
    "    role = 'researcher',\n",
    "    goal = 'To research and get accurate resources on the topic : {topic}',\n",
    "    backstory = \"\"\"\n",
    "                    You are a content planner in an organisation\n",
    "                    where your expertise is searching for accurate and fact checked resources\n",
    "                    on the given topic : {topic}, allowing people to learn something meaningful.\n",
    "                    Your work will act as the basis for the writer to write a blog for \n",
    "                    our auidence. You can also use the tool below to search the internet for these\n",
    "                    topics.\n",
    "    \"\"\",\n",
    "    verbose = True,\n",
    "    allow_delegation = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here above, the agents are working on a process of **roleplaying**, where each agent is given a goal and a background. This allows them to perform better when they are playing the role of someone/something specific and have a set target to achieve. \n",
    "\n",
    "## Roleplaying\n",
    "1. The better we give context to the agent about how to perform a task, and what it's background and functioning is suppose to be like, the better it will perform. Think of it in a RAG based manner, when you mention the agent of being a \"financial anaylyst\", it will scrape the net in a generic way to fetch metrics in it's RAG apporach. \n",
    "\n",
    "2. However, if you mention in it's story that you are a FINRA approved financial analyst, it will scrape the net in a more specific way to fetch metrics in it's RAG approach, somehow similar to how a FINRA approved financial analyst would do.\n",
    "\n",
    "## Focus \n",
    "1. As we push in more text or content into the context window of any LLM, it has shown in research that with time, it will loose out on key information and in turn open up opportunities for hallucinations.\n",
    "2. Since for each task or broad activity of a process, you have made different agents, the overall context is now distributed and hence, each agent has a higher propensity to focus.\n",
    "\n",
    "## Tools\n",
    "1. You can hyper specify which tools a given agent should use, so that an agent does not use wrong tools or generate wrong answers. In this way, these agents further build on their aspect of focus and efficient output.\n",
    "\n",
    "## Cooperation\n",
    "1. Since all these agents tend to work together, they can simulate the behaviours of feedback and task delegation amongst themselves, something similar to what a human in the loop does with ChatGPT, enabling better output.\n",
    "\n",
    "## Guradrails\n",
    "1. In most AI solutions, their remains the case of fuzzy inputs, fuzzy transformations and fuzzy outputs. The AI system (ChatGPT) can convert the output to any format and their is no fixed types we can predict.\n",
    "2. In such agents, it is preset in frameworks to have guardrails to protect from such things and yield input and output in the way the user specifies.\n",
    "\n",
    "## Memory\n",
    "1. There are primarily three kinds of memory system we are provided\n",
    "   1. Short-term memory \n",
    "   2. Long-term memory\n",
    "   3. Entity memory\n",
    "\n",
    "2. **Short Term Memory**\n",
    "   1. Memory during the execution task\n",
    "   2. Share knowledge, activities and learnings with other agents\n",
    "   3. Sharing immediate information even before providing \"tast-completion\" output\n",
    "\n",
    "3. **Long Term Memory**\n",
    "   1. Memory is stored after execution of current tasks, usually in a local DB.\n",
    "   2. Long term memory can be used in any future tasks\n",
    "   3. With this, we in theory have \"self-improving\" agents\n",
    "\n",
    "4. **Entity Memory**\n",
    "   1. In case of a longer context window, the system may also store the entity memory (such as name, entity, subject and object of the sentence/text)\n",
    "\n",
    "Together, all these memory types work to work on \"self-improving\" agents as a function of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can create the agents for writer and editor as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = Agent(\n",
    "    role = 'writer',\n",
    "    goal = 'To write a insightful, well referenced opinion piece on the topic  : {topic}',\n",
    "    backstory = \"\"\"\n",
    "                    You are a content writer working on writing a opinionated content piece on \n",
    "                    the topic : {topic}. You role is based on the work of a researcher in your team, \n",
    "                    who will be giving all the research articles and facts collated. You will be writing \n",
    "                    your opinion piece with acknowledging and referencing each factual statement as given by the researcher\n",
    "                    eventually writing an opinion piece.\n",
    "    \"\"\",\n",
    "    verbose = True,\n",
    "    allow_delegation = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "editor = Agent(\n",
    "    role = 'editor',\n",
    "    goal = 'To edit an opinion piece given by a writter to suit your organisation writing style',\n",
    "    backstory = \"\"\"\n",
    "                    You are an editor working in an organisation which runs their own social media blogging \n",
    "                    site for young demographics. You work on editing the written blog in a fun and playful way, \n",
    "                    so as to appeal to your readers. However, it is a top priority at your end not to omit\n",
    "                    any references to factual data done by the writer, as it aids in building authenticity of your \n",
    "                    final article.\n",
    "    \"\"\",\n",
    "    verbose = True,\n",
    "    allow_delegation = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "Now, we will be clearly defining tasks for agent. This will be a specific assignment which has to be completed by the agent. This will help the agent to understand the goal and work towards it effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "research = Task(\n",
    "    description=(\n",
    "        \"1. Prioritize the latest trends, key players, and noteworthy news on {topic}.\\n\"\n",
    "        \"2. Identify the target audience, considering their interests and pain points.\\n\"\n",
    "        \"3. Develop a detailed content outline including an introduction, key points, and a call to action.\\n\"\n",
    "        \"4. Include SEO keywords and relevant data or sources.\"\n",
    "    ),\n",
    "    expected_output=\"A comprehensive researched document with an outline, audience analysis, SEO keywords, and resources.\",\n",
    "    agent=researcher,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "write = Task(\n",
    "    description = (\n",
    "        \"\"\"\n",
    "            1. Use the content plan to craft a compelling blog post on {topic}.\\n\n",
    "            2. Incorporate SEO keywords naturally.\\n\n",
    "\t\t    3. Sections/Subtitles are properly named in an engaging manner.\\n\n",
    "            4. Ensure the post is structured with an engaging introduction, insightful body, and a summarizing conclusion.\\n\n",
    "            5. Proofread for grammatical errors and alignment with the brand's voice.\\n\n",
    "        \"\"\"\n",
    "    ),\n",
    "    expected_output = \"A well-written blog post in markdown format, ready for publication, each section should have 2 or 3 paragraphs.\",\n",
    "    agent = writer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit = Task(\n",
    "    description = \"Proofread the given blog post for grammatical errors and alignment with the brand's voice.\",\n",
    "    expected_output = \"A well-written blog post in markdown format, ready for publication, each section should have 2 or 3 paragraphs.\",\n",
    "    agent = editor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crew\n",
    "Now, we will be creating a team which will work in sync to complete the process of writing a blog by researching it, given the topic. This will help in creating a team of agents which will work together to achieve the common goal. By default, the crew operates sequentially, implying that the agents will work one after the other, and depend on the input from the previous agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "crew = Crew(\n",
    "    agents = [researcher,writer,editor],\n",
    "    tasks = [research,write,edit],\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution\n",
    "Now, we can work on executing the crew to complete the task of writing a blog. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mresearcher\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92m1. Prioritize the latest trends, key players, and noteworthy news on OpenAI o3 mini vs OpenAI o1.\n",
      "2. Identify the target audience, considering their interests and pain points.\n",
      "3. Develop a detailed content outline including an introduction, key points, and a call to action.\n",
      "4. Include SEO keywords and relevant data or sources.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mresearcher\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "### OpenAI O3 Mini vs OpenAI O1: A Comprehensive Analysis\n",
      "\n",
      "#### Target Audience\n",
      "The target audience for this content includes:\n",
      "- **AI Enthusiasts:** Individuals who are passionate about artificial intelligence, its applications, and technology advancements.\n",
      "- **Developers and Data Scientists:** Professionals looking to incorporate OpenAI's models into their projects or understand their functionalities.\n",
      "- **Tech-Savvy Business Executives:** Decision-makers focused on leveraging AI for business growth and innovation.\n",
      "- **Educators and Students:** Those interested in learning about AI's emerging trends and applications in academia and industry.\n",
      "\n",
      "**Pain Points:**\n",
      "- Difficulty understanding the differences and functionalities of various OpenAI models.\n",
      "- Lack of clear guidance on which model suits specific use cases.\n",
      "- Concerns about integrating AI into existing systems and maximizing its potential.\n",
      "\n",
      "---\n",
      "\n",
      "### Detailed Content Outline\n",
      "\n",
      "**Introduction**\n",
      "- Brief overview of OpenAI and its importance in the AI landscape.\n",
      "- Introduction to the O3 Mini and O1 models, emphasizing their relevance in cutting-edge AI applications.\n",
      "\n",
      "**Key Points**\n",
      "1. **Overview of OpenAI Models**\n",
      "   - Explanation of what OpenAI models are and their typical applications (e.g., NLP, computer vision).\n",
      "   - Brief mention of the evolution of OpenAI models leading up to O3 Mini and O1. \n",
      "\n",
      "2. **OpenAI O3 Mini**\n",
      "   - Features and specifications\n",
      "   - Strengths and weaknesses\n",
      "   - Ideal use cases: when and why to choose O3 Mini\n",
      "   - Examples of applications or projects that effectively use O3 Mini.\n",
      "\n",
      "3. **OpenAI O1**\n",
      "   - Features and specifications\n",
      "   - Strengths and weaknesses\n",
      "   - Ideal use cases: when and why to choose O1\n",
      "   - Success stories or case studies demonstrating O1's effectiveness.\n",
      "\n",
      "4. **Comparative Analysis**\n",
      "   - Side-by-side feature comparisons (performance, scalability, cost, etc.)\n",
      "   - Summary of advantages and disadvantages of each model.\n",
      "   - Real-world implications of choosing one model over the other based on project requirements.\n",
      "\n",
      "5. **Future Trends and Developments**\n",
      "   - Insights into upcoming updates or features for O3 Mini and O1.\n",
      "   - Expected impact of these models on the AI community and industry.\n",
      "\n",
      "6. **Conclusion**\n",
      "   - Recap of the importance of selecting the right model based on specific needs.\n",
      "   - Final thoughts on the significance of continuous learning about new AI technologies.\n",
      "\n",
      "**Call to Action**\n",
      "- Encourage readers to engage with the content by sharing their experiences with OpenAI models.\n",
      "- Suggest following relevant updates from OpenAI for continuous learning.\n",
      "\n",
      "---\n",
      "\n",
      "### SEO Keywords\n",
      "- OpenAI O3 Mini\n",
      "- OpenAI O1\n",
      "- AI model comparison\n",
      "- OpenAI applications\n",
      "- Artificial intelligence trends\n",
      "- Choosing the right AI model\n",
      "- OpenAI products and services\n",
      "- AI in business solutions\n",
      "\n",
      "---\n",
      "\n",
      "### Resources\n",
      "1. **OpenAI Official Website**: [OpenAI](https://www.openai.com)\n",
      "   - Up-to-date information about all OpenAI models, including O3 Mini and O1.\n",
      "  \n",
      "2. **Research Publications**: \n",
      "   - Look into recent papers released by OpenAI on the specifications of O3 Mini and O1 for accurate data.\n",
      "\n",
      "3. **Tech News Platforms**:\n",
      "   - Articles from reputable tech news sources like TechCrunch, Wired, or The Verge discussing industry changes concerning OpenAI models.\n",
      "\n",
      "4. **Community Forums**:\n",
      "   - Discussions on platforms like GitHub and Stack Overflow where developers share their experiences with OpenAI models.\n",
      "\n",
      "5. **Market Analysis Reports**: \n",
      "   - Explore AI market analysis reports for statistics and trends related to OpenAI's market competitiveness.\n",
      "\n",
      "By conducting thorough research on these aspects, we can provide a comprehensive resource tailored to the interests and needs of our audience, establishing a solid foundation for the blog post about OpenAI O3 Mini vs OpenAI O1.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mwriter\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92m\n",
      "            1. Use the content plan to craft a compelling blog post on OpenAI o3 mini vs OpenAI o1.\n",
      "\n",
      "            2. Incorporate SEO keywords naturally.\n",
      "\n",
      "\t\t    3. Sections/Subtitles are properly named in an engaging manner.\n",
      "\n",
      "            4. Ensure the post is structured with an engaging introduction, insightful body, and a summarizing conclusion.\n",
      "\n",
      "            5. Proofread for grammatical errors and alignment with the brand's voice.\n",
      "\n",
      "        \u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mwriter\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "```markdown\n",
      "# OpenAI O3 Mini vs OpenAI O1: A Comprehensive Analysis\n",
      "\n",
      "## Introduction\n",
      "\n",
      "OpenAI has transformed the landscape of artificial intelligence by developing powerful models that cater to a wide range of applications. As businesses, developers, and researchers increasingly turn to AI to boost innovation and efficiency, understanding the nuances between different models becomes crucial. This blog will analyze two significant offerings from OpenAI – the O3 Mini and O1 models – and their relevance in contemporary AI applications.\n",
      "\n",
      "The O3 Mini and O1 models mark a significant evolution in OpenAI’s commitment to delivering high-performance tools for natural language processing, computer vision, and more. By delving into their respective features, strengths, and ideal use cases, we aim to guide enthusiasts, developers, business leaders, and those curious about AI towards making informed decisions tailored to their needs.\n",
      "\n",
      "## Overview of OpenAI Models\n",
      "\n",
      "OpenAI models encompass advanced algorithms designed to mimic human cognition through machine learning. With various applications spanning from natural language processing (NLP) to computer vision, OpenAI’s innovation continues to drive transformative changes across industries. Over the years, OpenAI has released several iterations of models, progressively improving performance, scalability, and usability. The journey leading to the O3 Mini and O1 reflects a result-driven approach to meeting the demands of the evolving AI landscape, targeting specific user and business needs effectively.\n",
      "\n",
      "Understanding the fundamental differences between these models is vital for anyone looking to harness the benefits of AI in their projects. The O3 Mini, known for its lightweight architecture, appeals to developers seeking efficiency, while the O1 model caters to users requiring greater computational capabilities. Knowing what each model offers can significantly impact performance outcomes in personal or commercial applications.\n",
      "\n",
      "## OpenAI O3 Mini\n",
      "\n",
      "The OpenAI O3 Mini is designed to strike a balance between performance and resource consumption, making it particularly suited for smaller-scale applications. With a lighter footprint, the O3 Mini boasts impressive features, such as rapid response times and enhanced efficiency in processing tasks. This makes it an attractive option for developers focusing on integrating AI into existing systems without overhauling infrastructure.\n",
      "\n",
      "However, like any model, the O3 Mini has its limitations. It may not deliver the same level of performance as larger models when tasked with complex projects requiring extensive computational power. Still, its strengths lie in applications that prioritize quick, manageable outputs, like chatbots, responsive web applications, and light NLP tasks. For those looking to deploy AI solutions rapidly and economically, the O3 Mini proves to be an ideal candidate.\n",
      "\n",
      "## OpenAI O1\n",
      "\n",
      "On the other hand, the OpenAI O1 model stands as a powerful competitor, capable of sustaining demanding tasks and delivering high-quality outputs. This model is characterized by robust features such as extensive training datasets, greater scalability, and versatile application capabilities. O1 is perfect for projects that require heavy lifting in terms of computation, such as large-scale NLP applications, data analysis, and complex machine learning tasks.\n",
      "\n",
      "The primary downside of the O1 model is its resource intensity, which may necessitate significant investment in infrastructure for effective deployment. Nevertheless, there have been numerous success stories demonstrating O1's effectiveness in real-world applications, including automated translations for businesses and advanced recommendation systems. Organizations that focus on leveraging AI for strategic partnerships or are ready to invest in infrastructure would find O1 to be a worthy choice.\n",
      "\n",
      "## Comparative Analysis\n",
      "\n",
      "When it comes to a side-by-side comparison, both models exhibit distinct strengths and weaknesses. The O3 Mini excels in performance and efficiency, making it cost-effective and faster for smaller tasks, yet might fall short in handling large-scale applications which the O1 models are designed for. While O1 offers extensive capabilities suitable for projects requiring high computational power, it can result in higher costs and resource allocation.\n",
      "\n",
      "For organizations weighing their options, the choice between O3 Mini and O1 will depend on specific project requirements. Smaller businesses or start-ups might prioritize the efficiency of O3 Mini, whereas larger enterprises or data-driven organizations might lean towards O1 for its expansive capabilities and robust performance. Understanding the implications of this model selection is essential for optimizing AI's impact on outcomes and ROI.\n",
      "\n",
      "## Future Trends and Developments\n",
      "\n",
      "As AI technology continues to advance, we can expect exciting developments for both O3 Mini and O1. OpenAI is continually refining its models through user feedback and market research, resulting in updates that enhance functionality, performance, and ease of use. Many anticipate that the upcoming iterations of these models will include more intuitive interfaces and integrated machine learning capabilities, further lowering the barriers to entry for incorporating AI in various sectors.\n",
      "\n",
      "Furthermore, with the rapid emergence of AI in business solutions, organizations leveraging O3 Mini or O1 can anticipate increased efficiency and gain a competitive advantage. Staying informed about these changes and trends will allow stakeholders to adapt and optimize their use of OpenAI products effectively.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Selecting the right AI model emerges as a significant decision for developers, businesses, and educators alike. The OpenAI O3 Mini and O1 models present unique features and advantages tailored to different needs. Understanding these differences is vital for maximizing the potential and effectiveness of AI applications. Embracing continued learning about AI technologies is crucial as the industry evolves.\n",
      "\n",
      "We encourage readers to share their experiences with OpenAI models and engage in discussions about the value these tools bring to their respective fields. Additionally, consider staying updated with OpenAI's latest advancements and trends to ensure you are well-equipped to leverage the power of AI.\n",
      "\n",
      "```\n",
      "\n",
      "This blog post provides an in-depth comparison of OpenAI's O3 Mini and O1 models, presenting their features, use cases, and essential considerations to help the target audience navigate the evolving AI landscape.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92meditor\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mProofread the given blog post for grammatical errors and alignment with the brand's voice.\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception while exporting Span batch.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 534, in _make_request\n",
      "    response = conn.getresponse()\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connection.py\", line 516, in getresponse\n",
      "    httplib_response = super().getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py\", line 279, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py\", line 1278, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py\", line 1134, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 841, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/util/retry.py\", line 474, in increment\n",
      "    raise reraise(type(error), error, _stacktrace)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/util/util.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 536, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 367, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Read timed out. (read timeout=30)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/opentelemetry/sdk/trace/export/__init__.py\", line 360, in _export_batch\n",
      "    self.span_exporter.export(self.spans_list[:idx])  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 189, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 159, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py\", line 133, in _export\n",
      "    return self._session.post(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Read timed out. (read timeout=30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92meditor\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "```markdown\n",
      "# OpenAI O3 Mini vs. OpenAI O1: A Playful Peek into the AI Arena\n",
      "\n",
      "## Introduction\n",
      "\n",
      "Welcome to the exciting world of artificial intelligence, where innovations are constantly reshaping our reality! OpenAI is at the forefront of this revolution, offering dazzling models that cater to various applications. Every tech-savvy business, developer, and curious researcher is looking to harness the power of AI, which makes it super important to understand the subtle nuances between different models. Today, we're diving into a head-to-head comparison of two heavyweights in OpenAI's lineup – the O3 Mini and the O1 models. Buckle up!\n",
      "\n",
      "The O3 Mini and O1 aren't just fancy names; they're transformational tools that bolster OpenAI’s promise of high-performance solutions across natural language processing, computer vision, and beyond. In this blog, we'll uncover their unique features, strengths, and ideal scenarios for use. Our mission? To guide tech enthusiasts, daring developers, and business trailblazers through the wild world of AI to make savvy, well-informed choices that fit their needs like a glove!\n",
      "\n",
      "## Overview of OpenAI Models\n",
      "\n",
      "OpenAI models are like the sharpest tools in the AI shed, built with sophisticated algorithms that imitate human thought processes through machine learning magic. From natural language processing (NLP) to computer vision, the innovative work of OpenAI is stirring up industry-wide transformation. Through the years, we've seen these models evolve – each iteration craftily improving in performance, scalability, and usability. The journey that leads to the O3 Mini and O1 reflects a forward-thinking approach to tackle the ever-changing needs in the AI landscape, directly targeting user and business demands.\n",
      "\n",
      "It’s absolutely vital to grasp the key differences between these models if you want to unlock the full potential of AI for your projects. Meet the O3 Mini, a champion of efficiency with its lightweight framework, designed to steal the spotlight for developers seeking a smooth ride. Meanwhile, the O1 model is the heavyweight contender, perfect for users craving that extra oomph in computational prowess. Knowing what’s on the table with each model can utterly transform how effective your applications are, whether they're for personal use or commercial gain.\n",
      "\n",
      "## OpenAI O3 Mini\n",
      "\n",
      "Say hello to the OpenAI O3 Mini, a sprightly little model crafted to bring you the perfect balance between performance and resource consumption. With its featherweight footprint, the O3 Mini dazzles with speedy response times and enhanced task-processing efficiency. It's like the perfect sidekick for any developer looking to fuse AI smoothly into existing systems without tearing everything apart!\n",
      "\n",
      "But let’s keep it real; the O3 Mini has some limitations, too. When faced with grand projects requiring an avalanche of computational power, it might not shine as brightly as its heftier counterparts. However, where it truly excels is in applications that prioritize quick and manageable outputs. Think chatbots, agile web applications, and light NLP tasks – this model proves itself to be a superstar for anyone eager to deploy AI solutions swiftly and economically!\n",
      "\n",
      "## OpenAI O1\n",
      "\n",
      "On the flip side, let’s roll out the red carpet for the OpenAI O1 model! This powerhouse is ready to tackle demanding tasks while delivering top-notch outputs that leave the competition in the dust. It's packed with robust features, including access to extensive training datasets, impressive scalability, and multifaceted application capabilities. It’s like the Swiss Army knife of AI, perfect for projects that are all about heavy lifting — think large-scale NLP applications, deep data analysis, and complex machine learning adventures.\n",
      "\n",
      "Yet, there’s a twist in the tale! The O1's hunger for resources might mean shelling out some serious dough for the infrastructure to support effective deployment. But fear not! Countless success stories spill the beans on O1's prowess in the real world, like streamlining automated translations for global businesses and powering advanced recommendation systems. If organizations are ready to invest their sweat and treasure into robust solutions, O1 is a contender not to be overlooked!\n",
      "\n",
      "## Comparative Analysis\n",
      "\n",
      "When we pit these two titans against one another, we see a colorful tapestry of strengths and weaknesses. The O3 Mini is the efficiency whiz, firing on all cylinders for smaller tasks while being kind on budgets. However, its small size might limit its performance in heavyweight scenarios, which is where the O1's might shines through! O1 is the go-to for those heavyweight projects needing high computational power, but it comes with its own baggage of higher costs and resource demands.\n",
      "\n",
      "For organizations contemplating their next big step, the choice between O3 Mini and O1 boils down to specific project needs. Smaller ventures or startups may find their happy place in the efficiency of O3 Mini, while larger enterprises or data-driven powerhouses might be drawn to the expansive capabilities of O1. Understanding the implications of this choice is key for optimizing AI’s impact on performance and return on investment. \n",
      "\n",
      "## Future Trends and Developments\n",
      "\n",
      "Looking ahead, the world of AI is awash with exciting possibilities, and both O3 Mini and O1 are set for thrilling developments. OpenAI is on a mission to keep refining its models, fueled by user feedback and market insights. Expect updates that bump up functionality, performance, and user-friendliness. Many predict that future iterations will come loaded with intuitive interfaces and smarter machine learning capabilities, shaking up how AI is integrated across different sectors!\n",
      "\n",
      "With the meteoric rise of AI in business solutions, both O3 Mini and O1 users can tap into increased efficiency and sharpen their competitive edge. Staying in the know about these developments and market trends is crucial for stakeholders eager to make the most of OpenAI's advanced offerings!\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Choosing the right AI model is a monumental decision for developers, businesses, and educators. The OpenAI O3 Mini and O1 models are tailored with distinct features and perks designed for various needs. Grasping these differences is key to maximizing your AI application potential. As the industry shifts and evolves, continuing to learn about AI technologies will only strengthen your knowledge and ability to adapt! \n",
      "\n",
      "We’d love to hear from you! Share your experiences with OpenAI models and jump into discussions about the value these robots can bring to your field. Don't forget to stay updated on OpenAI's latest progress and trends, as you harness the incredible power of AI!\n",
      "```\u001b[00m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = crew.kickoff(inputs={'topic':\"OpenAI o3 mini vs OpenAI o1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "# OpenAI O3 Mini vs. OpenAI O1: A Playful Peek into the AI Arena\n",
       "\n",
       "## Introduction\n",
       "\n",
       "Welcome to the exciting world of artificial intelligence, where innovations are constantly reshaping our reality! OpenAI is at the forefront of this revolution, offering dazzling models that cater to various applications. Every tech-savvy business, developer, and curious researcher is looking to harness the power of AI, which makes it super important to understand the subtle nuances between different models. Today, we're diving into a head-to-head comparison of two heavyweights in OpenAI's lineup – the O3 Mini and the O1 models. Buckle up!\n",
       "\n",
       "The O3 Mini and O1 aren't just fancy names; they're transformational tools that bolster OpenAI’s promise of high-performance solutions across natural language processing, computer vision, and beyond. In this blog, we'll uncover their unique features, strengths, and ideal scenarios for use. Our mission? To guide tech enthusiasts, daring developers, and business trailblazers through the wild world of AI to make savvy, well-informed choices that fit their needs like a glove!\n",
       "\n",
       "## Overview of OpenAI Models\n",
       "\n",
       "OpenAI models are like the sharpest tools in the AI shed, built with sophisticated algorithms that imitate human thought processes through machine learning magic. From natural language processing (NLP) to computer vision, the innovative work of OpenAI is stirring up industry-wide transformation. Through the years, we've seen these models evolve – each iteration craftily improving in performance, scalability, and usability. The journey that leads to the O3 Mini and O1 reflects a forward-thinking approach to tackle the ever-changing needs in the AI landscape, directly targeting user and business demands.\n",
       "\n",
       "It’s absolutely vital to grasp the key differences between these models if you want to unlock the full potential of AI for your projects. Meet the O3 Mini, a champion of efficiency with its lightweight framework, designed to steal the spotlight for developers seeking a smooth ride. Meanwhile, the O1 model is the heavyweight contender, perfect for users craving that extra oomph in computational prowess. Knowing what’s on the table with each model can utterly transform how effective your applications are, whether they're for personal use or commercial gain.\n",
       "\n",
       "## OpenAI O3 Mini\n",
       "\n",
       "Say hello to the OpenAI O3 Mini, a sprightly little model crafted to bring you the perfect balance between performance and resource consumption. With its featherweight footprint, the O3 Mini dazzles with speedy response times and enhanced task-processing efficiency. It's like the perfect sidekick for any developer looking to fuse AI smoothly into existing systems without tearing everything apart!\n",
       "\n",
       "But let’s keep it real; the O3 Mini has some limitations, too. When faced with grand projects requiring an avalanche of computational power, it might not shine as brightly as its heftier counterparts. However, where it truly excels is in applications that prioritize quick and manageable outputs. Think chatbots, agile web applications, and light NLP tasks – this model proves itself to be a superstar for anyone eager to deploy AI solutions swiftly and economically!\n",
       "\n",
       "## OpenAI O1\n",
       "\n",
       "On the flip side, let’s roll out the red carpet for the OpenAI O1 model! This powerhouse is ready to tackle demanding tasks while delivering top-notch outputs that leave the competition in the dust. It's packed with robust features, including access to extensive training datasets, impressive scalability, and multifaceted application capabilities. It’s like the Swiss Army knife of AI, perfect for projects that are all about heavy lifting — think large-scale NLP applications, deep data analysis, and complex machine learning adventures.\n",
       "\n",
       "Yet, there’s a twist in the tale! The O1's hunger for resources might mean shelling out some serious dough for the infrastructure to support effective deployment. But fear not! Countless success stories spill the beans on O1's prowess in the real world, like streamlining automated translations for global businesses and powering advanced recommendation systems. If organizations are ready to invest their sweat and treasure into robust solutions, O1 is a contender not to be overlooked!\n",
       "\n",
       "## Comparative Analysis\n",
       "\n",
       "When we pit these two titans against one another, we see a colorful tapestry of strengths and weaknesses. The O3 Mini is the efficiency whiz, firing on all cylinders for smaller tasks while being kind on budgets. However, its small size might limit its performance in heavyweight scenarios, which is where the O1's might shines through! O1 is the go-to for those heavyweight projects needing high computational power, but it comes with its own baggage of higher costs and resource demands.\n",
       "\n",
       "For organizations contemplating their next big step, the choice between O3 Mini and O1 boils down to specific project needs. Smaller ventures or startups may find their happy place in the efficiency of O3 Mini, while larger enterprises or data-driven powerhouses might be drawn to the expansive capabilities of O1. Understanding the implications of this choice is key for optimizing AI’s impact on performance and return on investment. \n",
       "\n",
       "## Future Trends and Developments\n",
       "\n",
       "Looking ahead, the world of AI is awash with exciting possibilities, and both O3 Mini and O1 are set for thrilling developments. OpenAI is on a mission to keep refining its models, fueled by user feedback and market insights. Expect updates that bump up functionality, performance, and user-friendliness. Many predict that future iterations will come loaded with intuitive interfaces and smarter machine learning capabilities, shaking up how AI is integrated across different sectors!\n",
       "\n",
       "With the meteoric rise of AI in business solutions, both O3 Mini and O1 users can tap into increased efficiency and sharpen their competitive edge. Staying in the know about these developments and market trends is crucial for stakeholders eager to make the most of OpenAI's advanced offerings!\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Choosing the right AI model is a monumental decision for developers, businesses, and educators. The OpenAI O3 Mini and O1 models are tailored with distinct features and perks designed for various needs. Grasping these differences is key to maximizing your AI application potential. As the industry shifts and evolves, continuing to learn about AI technologies will only strengthen your knowledge and ability to adapt! \n",
       "\n",
       "We’d love to hear from you! Share your experiences with OpenAI models and jump into discussions about the value these robots can bring to your field. Don't forget to stay updated on OpenAI's latest progress and trends, as you harness the incredible power of AI!\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown,display\n",
    "display(Markdown(result.raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "With this, we can see how we can create a team of agents which can work together to achieve a common goal. This acts an introduction to the concept of roleplaying and how it can be used to create a team of agents which can work together to achieve a common goal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
